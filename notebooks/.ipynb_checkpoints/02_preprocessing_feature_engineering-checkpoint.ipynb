{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c86af157-798e-4af4-990d-07f22fbdb633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T07:19:08.313308Z",
     "iopub.status.busy": "2025-10-23T07:19:08.312976Z",
     "iopub.status.idle": "2025-10-23T07:19:33.604828Z",
     "shell.execute_reply": "2025-10-23T07:19:33.604003Z",
     "shell.execute_reply.started": "2025-10-23T07:19:08.313286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "‚öôÔ∏è PREPROCESSING AVANC√â ET FEATURE ENGINEERING\n",
      "======================================================================\n",
      "\n",
      "CHARGEMENT DES DONN√âES FUSIONN√âES\n",
      "----------------------------------------------------------------------\n",
      "Dataset charg√© : (100000, 27)\n",
      "   - 100,000 interactions\n",
      "   - 27 colonnes\n",
      "\n",
      "======================================================================\n",
      "FEATURE ENGINEERING - PROFIL UTILISATEUR\n",
      "======================================================================\n",
      "\n",
      "üîπ Encodage du genre (One-Hot)\n",
      "Colonnes cr√©√©es : gender_M, gender_F\n",
      "\n",
      " Normalisation de l'√¢ge\n",
      "√Çge normalis√© entre 0 et 1\n",
      "   Age min: 7 ‚Üí 0.00\n",
      "   Age max: 73 ‚Üí 1.00\n",
      "\n",
      "üîπ Cr√©ation de cat√©gories d'√¢ge\n",
      " Cat√©gories cr√©√©es : <18, 18-25, 26-35, 36-50, 50+\n",
      "age_group\n",
      "<18       4710\n",
      "18-25    25854\n",
      "26-35    34794\n",
      "36-50    25184\n",
      "50+       9458\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üîπ Encodage de la profession (Label Encoding)\n",
      " 21 professions encod√©es\n",
      "\n",
      "üîπ Calcul de l'activit√© utilisateur\n",
      " Features cr√©√©es :\n",
      "   - user_rating_count : nombre total de ratings\n",
      "   - user_avg_rating : rating moyen de l'utilisateur\n",
      "   - user_rating_std : √©cart-type des ratings\n",
      "   - user_unique_items : nombre de films diff√©rents not√©s\n",
      "\n",
      "======================================================================\n",
      " FEATURE ENGINEERING - PROFIL FILM\n",
      "======================================================================\n",
      "\n",
      "üîπ Calcul du nombre de genres par film\n",
      " Moyenne de genres par film : 2.13\n",
      "\n",
      "üîπ Calcul de la popularit√© et qualit√© des films\n",
      " Features cr√©√©es :\n",
      "   - item_rating_count : nombre total de ratings re√ßus\n",
      "   - item_avg_rating : rating moyen du film\n",
      "   - item_rating_std : √©cart-type (controverse)\n",
      "   - item_unique_users : nombre d'utilisateurs ayant not√©\n",
      "\n",
      "üîπ Transformation log de la popularit√©\n",
      " item_popularity_log cr√©√©e (√©chelle logarithmique)\n",
      "\n",
      "======================================================================\n",
      " FEATURE ENGINEERING - TEMPOREL\n",
      "======================================================================\n",
      "\n",
      "üîπ Conversion des timestamps\n",
      " Features temporelles cr√©√©es :\n",
      "   - P√©riode des donn√©es : 1997-09-20 03:05:10 √† 1998-04-22 23:10:38\n",
      "   - Ann√©es : 1997 - 1998\n",
      "\n",
      " Cat√©gorisation de la p√©riode de la journ√©e\n",
      " P√©riodes : morning, afternoon, evening, night\n",
      "time_of_day\n",
      "night        41153\n",
      "evening      28323\n",
      "afternoon    20578\n",
      "morning       9946\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      " FEATURES D'INTERACTION\n",
      "======================================================================\n",
      "\n",
      " √âcart par rapport √† la moyenne utilisateur\n",
      " rating_diff_user_avg cr√©√©e\n",
      "\n",
      " √âcart par rapport √† la moyenne du film\n",
      " rating_diff_item_avg cr√©√©e\n",
      "\n",
      " Calcul des pr√©f√©rences de genre par utilisateur\n",
      "\n",
      " Calcul du score de match genre\n",
      " genre_match_score cr√©√©e (similarit√© utilisateur-film)\n",
      "\n",
      "======================================================================\n",
      " ENCODAGE DES IDENTIFIANTS\n",
      "======================================================================\n",
      "\n",
      " Encodage des user_id et item_id\n",
      " Utilisateurs encod√©s : 0 √† 942\n",
      " Films encod√©s : 0 √† 1681\n",
      "Encoders sauvegard√©s dans models/encoders/\n",
      "\n",
      "======================================================================\n",
      " S√âLECTION DES FEATURES POUR LE MOD√àLE\n",
      "======================================================================\n",
      " 21 features s√©lectionn√©es :\n",
      "    1. user\n",
      "    2. item\n",
      "    3. age_normalized\n",
      "    4. gender_M\n",
      "    5. gender_F\n",
      "    6. occupation_encoded\n",
      "    7. user_rating_count\n",
      "    8. user_avg_rating\n",
      "    9. user_rating_std\n",
      "   10. num_genres\n",
      "   11. item_rating_count\n",
      "   12. item_avg_rating\n",
      "   13. item_rating_std\n",
      "   14. item_popularity_log\n",
      "   15. year\n",
      "   16. month\n",
      "   17. day_of_week\n",
      "   18. hour\n",
      "   19. genre_match_score\n",
      "   20. rating_diff_user_avg\n",
      "   21. rating_diff_item_avg\n",
      "\n",
      "======================================================================\n",
      " S√âPARATION TRAIN / TEST\n",
      "======================================================================\n",
      "\n",
      "üîπ Strat√©gie : Split temporel (80/20)\n",
      " Train : 80,000 samples (80.0%)\n",
      " Test  : 20,000 samples (20.0%)\n",
      "\n",
      " Distribution des ratings :\n",
      "   Train - Moyenne : 3.518, Std : 1.127\n",
      "   Test  - Moyenne : 3.579, Std : 1.117\n",
      "\n",
      "======================================================================\n",
      " NORMALISATION DES FEATURES NUM√âRIQUES\n",
      "======================================================================\n",
      "\n",
      "üîπ Normalisation de 8 features num√©riques\n",
      "Normalisation appliqu√©e (moyenne=0, std=1)\n",
      "Scaler sauvegard√©\n",
      "\n",
      "======================================================================\n",
      "SAUVEGARDE DES DONN√âES PR√âPAR√âES\n",
      "======================================================================\n",
      "Fichiers sauvegard√©s :\n",
      "   - data/processed/train_features.csv\n",
      "   - data/processed/test_features.csv\n",
      "Versions compactes sauvegard√©es\n",
      "\n",
      "======================================================================\n",
      "VISUALISATION DES FEATURES\n",
      "======================================================================\n",
      "Graphique sauvegard√© : outputs/plots/03_feature_engineering.png\n",
      "\n",
      "======================================================================\n",
      "G√âN√âRATION DU RAPPORT\n",
      "======================================================================\n",
      "Rapport JSON sauvegard√© : outputs/metrics/preprocessing_report.json\n",
      "\n",
      "======================================================================\n",
      "PREPROCESSING TERMIN√â AVEC SUCC√àS\n",
      "======================================================================\n",
      "\n",
      "R√âSUM√â :\n",
      " 21 features cr√©√©es\n",
      " Train : 80,000 samples\n",
      " Test  : 20,000 samples\n",
      " Donn√©es normalis√©es et pr√™tes pour l'entra√Ænement\n",
      "\n",
      "üéØ FEATURES CR√â√âES :\n",
      "  üë§ Utilisateur : profil d√©mographique + activit√©\n",
      "  üé¨ Film : popularit√© + qualit√© + genres\n",
      "  üïí Temporel : year, month, day, hour, period\n",
      "  üîó Interaction : genre matching + √©carts moyennes\n",
      "\n",
      "üöÄ PROCHAINE √âTAPE : Entra√Ænement du Mod√®le avec M√©triques Avanc√©es\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=====================================================================\n",
    "NOTEBOOK 2 : PREPROCESSING AVANC√â ET FEATURE ENGINEERING\n",
    "Projet : Syst√®me de Recommandation MovieLens sur Amazon SageMaker\n",
    "Auteur : Gninninmaguignon Silu√©\n",
    "Date : Octobre 2025\n",
    "=====================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PREPROCESSING AVANC√â ET FEATURE ENGINEERING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 1 : CHARGEMENT DES DONN√âES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nCHARGEMENT DES DONN√âES FUSIONN√âES\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Charger le dataset complet cr√©√© pr√©c√©demment\n",
    "data = pd.read_csv(\"../data/processed/movielens_complete.csv\")\n",
    "movies = pd.read_csv(\"../data/processed/movies_metadata.csv\")\n",
    "users = pd.read_csv(\"../data/processed/users_metadata.csv\")\n",
    "\n",
    "print(f\"Dataset charg√© : {data.shape}\")\n",
    "print(f\"   - {data.shape[0]:,} interactions\")\n",
    "print(f\"   - {data.shape[1]} colonnes\")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 2 : FEATURE ENGINEERING - UTILISATEURS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE ENGINEERING - PROFIL UTILISATEUR\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 2.1 : Encodage du genre\n",
    "print(\"\\nüîπ Encodage du genre (One-Hot)\")\n",
    "data['gender_M'] = (data['gender'] == 'M').astype(int)\n",
    "data['gender_F'] = (data['gender'] == 'F').astype(int)\n",
    "print(\"Colonnes cr√©√©es : gender_M, gender_F\")\n",
    "\n",
    "# 2.2 : Normalisation de l'√¢ge\n",
    "print(\"\\n Normalisation de l'√¢ge\")\n",
    "scaler_age = MinMaxScaler()\n",
    "data['age_normalized'] = scaler_age.fit_transform(data[['age']])\n",
    "print(f\"√Çge normalis√© entre 0 et 1\")\n",
    "print(f\"   Age min: {data['age'].min()} ‚Üí {data['age_normalized'].min():.2f}\")\n",
    "print(f\"   Age max: {data['age'].max()} ‚Üí {data['age_normalized'].max():.2f}\")\n",
    "\n",
    "# 2.3 : Cat√©gories d'√¢ge\n",
    "print(\"\\nüîπ Cr√©ation de cat√©gories d'√¢ge\")\n",
    "data['age_group'] = pd.cut(data['age'], \n",
    "                            bins=[0, 18, 25, 35, 50, 100],\n",
    "                            labels=['<18', '18-25', '26-35', '36-50', '50+'])\n",
    "print(\" Cat√©gories cr√©√©es : <18, 18-25, 26-35, 36-50, 50+\")\n",
    "print(data['age_group'].value_counts().sort_index())\n",
    "\n",
    "# 2.4 : Encodage de la profession\n",
    "print(\"\\nüîπ Encodage de la profession (Label Encoding)\")\n",
    "le_occupation = LabelEncoder()\n",
    "data['occupation_encoded'] = le_occupation.fit_transform(data['occupation'])\n",
    "print(f\" {len(le_occupation.classes_)} professions encod√©es\")\n",
    "\n",
    "# 2.5 : Statistiques utilisateur (activit√©)\n",
    "print(\"\\nüîπ Calcul de l'activit√© utilisateur\")\n",
    "user_stats = data.groupby('user_id').agg({\n",
    "    'rating': ['count', 'mean', 'std'],\n",
    "    'item_id': 'nunique'\n",
    "}).reset_index()\n",
    "user_stats.columns = ['user_id', 'user_rating_count', 'user_avg_rating', \n",
    "                      'user_rating_std', 'user_unique_items']\n",
    "\n",
    "# G√©rer les NaN dans std (utilisateurs avec 1 seul rating)\n",
    "user_stats['user_rating_std'].fillna(0, inplace=True)\n",
    "\n",
    "data = data.merge(user_stats, on='user_id', how='left')\n",
    "print(\" Features cr√©√©es :\")\n",
    "print(\"   - user_rating_count : nombre total de ratings\")\n",
    "print(\"   - user_avg_rating : rating moyen de l'utilisateur\")\n",
    "print(\"   - user_rating_std : √©cart-type des ratings\")\n",
    "print(\"   - user_unique_items : nombre de films diff√©rents not√©s\")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 3 : FEATURE ENGINEERING - FILMS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" FEATURE ENGINEERING - PROFIL FILM\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 3.1 : Nombre de genres par film\n",
    "print(\"\\nüîπ Calcul du nombre de genres par film\")\n",
    "genre_cols = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy',\n",
    "              'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir',\n",
    "              'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "              'Thriller', 'War', 'Western']\n",
    "data['num_genres'] = data[genre_cols].sum(axis=1)\n",
    "print(f\" Moyenne de genres par film : {data['num_genres'].mean():.2f}\")\n",
    "\n",
    "# 3.2 : Statistiques film (popularit√© et qualit√©)\n",
    "print(\"\\nüîπ Calcul de la popularit√© et qualit√© des films\")\n",
    "item_stats = data.groupby('item_id').agg({\n",
    "    'rating': ['count', 'mean', 'std'],\n",
    "    'user_id': 'nunique'\n",
    "}).reset_index()\n",
    "item_stats.columns = ['item_id', 'item_rating_count', 'item_avg_rating',\n",
    "                      'item_rating_std', 'item_unique_users']\n",
    "\n",
    "# G√©rer les NaN\n",
    "item_stats['item_rating_std'].fillna(0, inplace=True)\n",
    "\n",
    "data = data.merge(item_stats, on='item_id', how='left')\n",
    "print(\" Features cr√©√©es :\")\n",
    "print(\"   - item_rating_count : nombre total de ratings re√ßus\")\n",
    "print(\"   - item_avg_rating : rating moyen du film\")\n",
    "print(\"   - item_rating_std : √©cart-type (controverse)\")\n",
    "print(\"   - item_unique_users : nombre d'utilisateurs ayant not√©\")\n",
    "\n",
    "# 3.3 : Popularit√© relative (log-transform pour r√©duire skewness)\n",
    "print(\"\\nüîπ Transformation log de la popularit√©\")\n",
    "data['item_popularity_log'] = np.log1p(data['item_rating_count'])\n",
    "print(\" item_popularity_log cr√©√©e (√©chelle logarithmique)\")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 4 : FEATURES TEMPORELLES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" FEATURE ENGINEERING - TEMPOREL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 4.1 : Conversion du timestamp\n",
    "print(\"\\nüîπ Conversion des timestamps\")\n",
    "data['datetime'] = pd.to_datetime(data['timestamp'], unit='s')\n",
    "data['year'] = data['datetime'].dt.year\n",
    "data['month'] = data['datetime'].dt.month\n",
    "data['day_of_week'] = data['datetime'].dt.dayofweek\n",
    "data['hour'] = data['datetime'].dt.hour\n",
    "\n",
    "print(\" Features temporelles cr√©√©es :\")\n",
    "print(f\"   - P√©riode des donn√©es : {data['datetime'].min()} √† {data['datetime'].max()}\")\n",
    "print(f\"   - Ann√©es : {data['year'].min()} - {data['year'].max()}\")\n",
    "\n",
    "# 4.2 : P√©riode de la journ√©e\n",
    "print(\"\\n Cat√©gorisation de la p√©riode de la journ√©e\")\n",
    "def get_time_of_day(hour):\n",
    "    if 6 <= hour < 12:\n",
    "        return 'morning'\n",
    "    elif 12 <= hour < 18:\n",
    "        return 'afternoon'\n",
    "    elif 18 <= hour < 22:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "data['time_of_day'] = data['hour'].apply(get_time_of_day)\n",
    "print(\" P√©riodes : morning, afternoon, evening, night\")\n",
    "print(data['time_of_day'].value_counts())\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 5 : FEATURES D'INTERACTION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" FEATURES D'INTERACTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 5.1 : Diff√©rence par rapport √† la moyenne utilisateur\n",
    "print(\"\\n √âcart par rapport √† la moyenne utilisateur\")\n",
    "data['rating_diff_user_avg'] = data['rating'] - data['user_avg_rating']\n",
    "print(\" rating_diff_user_avg cr√©√©e\")\n",
    "\n",
    "# 5.2 : Diff√©rence par rapport √† la moyenne du film\n",
    "print(\"\\n √âcart par rapport √† la moyenne du film\")\n",
    "data['rating_diff_item_avg'] = data['rating'] - data['item_avg_rating']\n",
    "print(\" rating_diff_item_avg cr√©√©e\")\n",
    "\n",
    "# 5.3 : Genre matching (similarit√© utilisateur-film)\n",
    "# Calculer les pr√©f√©rences de genre par utilisateur\n",
    "print(\"\\n Calcul des pr√©f√©rences de genre par utilisateur\")\n",
    "user_genre_prefs = data.groupby('user_id')[genre_cols].mean()\n",
    "user_genre_prefs.columns = [f'user_pref_{col}' for col in genre_cols]\n",
    "data = data.merge(user_genre_prefs, left_on='user_id', right_index=True, how='left')\n",
    "\n",
    "# Score de match genre\n",
    "print(\"\\n Calcul du score de match genre\")\n",
    "genre_match_scores = []\n",
    "for idx, row in data.iterrows():\n",
    "    score = sum([row[genre] * row[f'user_pref_{genre}'] for genre in genre_cols])\n",
    "    genre_match_scores.append(score)\n",
    "data['genre_match_score'] = genre_match_scores\n",
    "print(\" genre_match_score cr√©√©e (similarit√© utilisateur-film)\")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 6 : ENCODAGE DES IDs\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" ENCODAGE DES IDENTIFIANTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n Encodage des user_id et item_id\")\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "data['user'] = user_encoder.fit_transform(data['user_id'])\n",
    "data['item'] = item_encoder.fit_transform(data['item_id'])\n",
    "\n",
    "print(f\" Utilisateurs encod√©s : 0 √† {data['user'].max()}\")\n",
    "print(f\" Films encod√©s : 0 √† {data['item'].max()}\")\n",
    "\n",
    "# Sauvegarder les encoders\n",
    "import pickle\n",
    "os.makedirs('../models/encoders', exist_ok=True)\n",
    "with open('../models/encoders/user_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(user_encoder, f)\n",
    "with open('models/encoders/item_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(item_encoder, f)\n",
    "print(\"Encoders sauvegard√©s dans models/encoders/\")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 7 : S√âLECTION DES FEATURES FINALES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" S√âLECTION DES FEATURES POUR LE MOD√àLE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Features pour le mod√®le\n",
    "feature_columns = [\n",
    "    # IDs encod√©s\n",
    "    'user', 'item',\n",
    "\n",
    "    # Features utilisateur\n",
    "    'age_normalized', 'gender_M', 'gender_F', 'occupation_encoded',\n",
    "    'user_rating_count', 'user_avg_rating', 'user_rating_std',\n",
    "\n",
    "    # Features film\n",
    "    'num_genres', 'item_rating_count', 'item_avg_rating', \n",
    "    'item_rating_std', 'item_popularity_log',\n",
    "\n",
    "    # Features temporelles\n",
    "    'year', 'month', 'day_of_week', 'hour',\n",
    "    \n",
    "    # Features d'interaction\n",
    "    'genre_match_score', 'rating_diff_user_avg', 'rating_diff_item_avg'\n",
    "]\n",
    "\n",
    "# Features de genre (optionnel, √† activer si besoin)\n",
    "# feature_columns += genre_cols\n",
    "\n",
    "print(f\" {len(feature_columns)} features s√©lectionn√©es :\")\n",
    "for i, feat in enumerate(feature_columns, 1):\n",
    "    print(f\"   {i:2d}. {feat}\")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 8 : TRAIN/TEST SPLIT\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" S√âPARATION TRAIN / TEST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Strat√©gie : split temporel (plus r√©aliste pour les syst√®mes de recommandation)\n",
    "print(\"\\nüîπ Strat√©gie : Split temporel (80/20)\")\n",
    "data_sorted = data.sort_values('timestamp')\n",
    "split_idx = int(len(data_sorted) * 0.8)\n",
    "\n",
    "train_data = data_sorted.iloc[:split_idx].copy()\n",
    "test_data = data_sorted.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\" Train : {len(train_data):,} samples ({len(train_data)/len(data)*100:.1f}%)\")\n",
    "print(f\" Test  : {len(test_data):,} samples ({len(test_data)/len(data)*100:.1f}%)\")\n",
    "\n",
    "# V√©rification de la distribution\n",
    "print(f\"\\n Distribution des ratings :\")\n",
    "print(f\"   Train - Moyenne : {train_data['rating'].mean():.3f}, Std : {train_data['rating'].std():.3f}\")\n",
    "print(f\"   Test  - Moyenne : {test_data['rating'].mean():.3f}, Std : {test_data['rating'].std():.3f}\")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 9 : NORMALISATION DES FEATURES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" NORMALISATION DES FEATURES NUM√âRIQUES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Features √† normaliser (exclure les IDs et features d√©j√† normalis√©es)\n",
    "features_to_scale = [\n",
    "    'user_rating_count', 'user_rating_std',\n",
    "    'item_rating_count', 'item_rating_std', 'item_popularity_log',\n",
    "    'genre_match_score', 'rating_diff_user_avg', 'rating_diff_item_avg'\n",
    "]\n",
    "\n",
    "print(f\"\\nüîπ Normalisation de {len(features_to_scale)} features num√©riques\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit sur le train uniquement\n",
    "train_data[features_to_scale] = scaler.fit_transform(train_data[features_to_scale])\n",
    "test_data[features_to_scale] = scaler.transform(test_data[features_to_scale])\n",
    "\n",
    "print(\"Normalisation appliqu√©e (moyenne=0, std=1)\")\n",
    "\n",
    "# Sauvegarder le scaler\n",
    "with open('models/encoders/feature_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"Scaler sauvegard√©\")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 10 : SAUVEGARDE DES DONN√âES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SAUVEGARDE DES DONN√âES PR√âPAR√âES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Sauvegarder train/test\n",
    "train_data.to_csv(\"../data/processed/train_features.csv\", index=False)\n",
    "test_data.to_csv(\"../data/processed/test_features.csv\", index=False)\n",
    "print(\"Fichiers sauvegard√©s :\")\n",
    "print(\"   - data/processed/train_features.csv\")\n",
    "print(\"   - data/processed/test_features.csv\")\n",
    "\n",
    "# Sauvegarder uniquement les colonnes n√©cessaires (l√©ger)\n",
    "train_compact = train_data[feature_columns + ['rating']]\n",
    "test_compact = test_data[feature_columns + ['rating']]\n",
    "\n",
    "train_compact.to_csv(\"../data/processed/train_compact.csv\", index=False)\n",
    "test_compact.to_csv(\"../data/processed/test_compact.csv\", index=False)\n",
    "print(\"Versions compactes sauvegard√©es\")\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 11 : VISUALISATION DES FEATURES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VISUALISATION DES FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Distribution des Features Principales', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. User rating count\n",
    "axes[0, 0].hist(train_data['user_rating_count'], bins=50, color='steelblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Activit√© Utilisateur')\n",
    "axes[0, 0].set_xlabel('Nombre de ratings')\n",
    "axes[0, 0].set_ylabel('Fr√©quence')\n",
    "\n",
    "# 2. Item popularity\n",
    "axes[0, 1].hist(train_data['item_popularity_log'], bins=50, color='coral', edgecolor='black')\n",
    "axes[0, 1].set_title('Popularit√© des Films (log)')\n",
    "axes[0, 1].set_xlabel('Log(nombre de ratings)')\n",
    "axes[0, 1].set_ylabel('Fr√©quence')\n",
    "\n",
    "# 3. Age distribution\n",
    "axes[0, 2].hist(train_data['age'], bins=30, color='mediumseagreen', edgecolor='black')\n",
    "axes[0, 2].set_title('Distribution de l\\'√Çge')\n",
    "axes[0, 2].set_xlabel('√Çge')\n",
    "axes[0, 2].set_ylabel('Fr√©quence')\n",
    "\n",
    "# 4. Genre match score\n",
    "axes[1, 0].hist(train_data['genre_match_score'], bins=50, color='mediumpurple', edgecolor='black')\n",
    "axes[1, 0].set_title('Score de Match Genre')\n",
    "axes[1, 0].set_xlabel('Score')\n",
    "axes[1, 0].set_ylabel('Fr√©quence')\n",
    "\n",
    "# 5. Time of day\n",
    "time_counts = train_data['time_of_day'].value_counts()\n",
    "axes[1, 1].bar(time_counts.index, time_counts.values, color=['#f39c12', '#e74c3c', '#9b59b6', '#34495e'])\n",
    "axes[1, 1].set_title('Ratings par P√©riode')\n",
    "axes[1, 1].set_xlabel('P√©riode de la journ√©e')\n",
    "axes[1, 1].set_ylabel('Nombre de ratings')\n",
    "\n",
    "# 6. Correlation heatmap (top features)\n",
    "top_features = ['rating', 'user_avg_rating', 'item_avg_rating', \n",
    "                'genre_match_score', 'item_popularity_log']\n",
    "corr_matrix = train_data[top_features].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            ax=axes[1, 2], cbar_kws={'shrink': 0.8})\n",
    "axes[1, 2].set_title('Corr√©lations Features-Target')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/plots/03_feature_engineering.png', dpi=150, bbox_inches='tight')\n",
    "print(\"Graphique sauvegard√© : outputs/plots/03_feature_engineering.png\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================\n",
    "# PARTIE 12 : RAPPORT DE PREPROCESSING\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"G√âN√âRATION DU RAPPORT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "report = {\n",
    "    'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'dataset': {\n",
    "        'total_samples': len(data),\n",
    "        'train_samples': len(train_data),\n",
    "        'test_samples': len(test_data),\n",
    "        'n_users': int(data['user_id'].nunique()),\n",
    "        'n_items': int(data['item_id'].nunique())\n",
    "    },\n",
    "    'features': {\n",
    "        'total_features': len(feature_columns),\n",
    "        'feature_list': feature_columns,\n",
    "        'user_features': 7,\n",
    "        'item_features': 5,\n",
    "        'temporal_features': 4,\n",
    "        'interaction_features': 3\n",
    "    },\n",
    "    'preprocessing': {\n",
    "        'encoding': ['user_id', 'item_id', 'occupation'],\n",
    "        'normalization': features_to_scale,\n",
    "        'split_strategy': 'temporal',\n",
    "        'train_ratio': 0.8\n",
    "    },\n",
    "    'statistics': {\n",
    "        'train_rating_mean': float(train_data['rating'].mean()),\n",
    "        'test_rating_mean': float(test_data['rating'].mean()),\n",
    "        'sparsity': 93.70\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('../outputs/metrics/preprocessing_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "print(\"Rapport JSON sauvegard√© : outputs/metrics/preprocessing_report.json\")\n",
    "\n",
    "# ============================================\n",
    "# R√âSUM√â FINAL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PREPROCESSING TERMIN√â AVEC SUCC√àS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nR√âSUM√â :\")\n",
    "print(f\" {len(feature_columns)} features cr√©√©es\")\n",
    "print(f\" Train : {len(train_data):,} samples\")\n",
    "print(f\" Test  : {len(test_data):,} samples\")\n",
    "print(f\" Donn√©es normalis√©es et pr√™tes pour l'entra√Ænement\")\n",
    "\n",
    "print(\"\\nFEATURES CR√â√âES :\")\n",
    "print(\" Utilisateur : profil d√©mographique + activit√©\")\n",
    "print(\" Film : popularit√© + qualit√© + genres\")\n",
    "print(\"  Temporel : year, month, day, hour, period\")\n",
    "print(\" Interaction : genre matching + √©carts moyennes\")\n",
    "\n",
    "print(\"\\nPROCHAINE √âTAPE : Entra√Ænement du Mod√®le avec M√©triques Avanc√©es\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5be996-71bd-49bd-a185-accd1a4a0a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
